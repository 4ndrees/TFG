{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alexnet is not recommended. Use the imagePretrainedNetwork function instead and specify the \"alexnet\" model. For more information, see Version History."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no plans to remove support for the alexnet function. However, the imagePretrainedNetwork function has additional functionality that helps with transfer learning workflows. For example, you can specify the number of classes in your data using the numClasses option, and the function returns a network that is ready for retraining without the need for modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En MATLAB, la advertencia sobre AlexNet se debe probablemente a que:\n",
    "\n",
    "AlexNet es un modelo más antiguo (2012), y desde entonces han aparecido modelos más eficientes, precisos y avanzados como VGG, ResNet, y EfficientNet.\n",
    "MATLAB ha mejorado su API con nuevas funciones, como imagePretrainedNetwork, para gestionar modelos preentrenados de manera más flexible.\n",
    "MATLAB está empujando a los usuarios hacia modelos más modernos que ofrezcan mejor rendimiento en términos de precisión y eficiencia computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque AlexNet está algo desactualizado en comparación con modelos modernos, AlexNet todavía puede ser útil en ciertas situaciones:\n",
    "\n",
    "Simplicidad: Es una red relativamente simple y menos profunda, por lo que es una excelente opción para estudiantes o personas que recién comienzan con redes neuronales.\n",
    "Menos demandante computacionalmente: Debido a su simplicidad, puede ser más rápido y menos costoso en términos de recursos de cómputo. Esto puede ser útil si no tienes acceso a hardware potente (como GPUs) o si solo necesitas una red rápida para pruebas.\n",
    "Benchmarking: AlexNet se sigue utilizando como referencia en papers o experimentos para comparar con modelos más recientes.\n",
    "Propósitos educativos: Es un buen modelo para aprender conceptos básicos de redes convolucionales, ya que fue uno de los primeros modelos que demostró el poder de las CNNs en el conjunto de datos ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tu objetivo es rendimiento o precisión, en lugar de usar AlexNet, sería mejor optar por modelos más modernos y eficientes. Aquí algunos que son ampliamente recomendados y disponibles tanto en MATLAB como en Python (usando PyTorch o TensorFlow):\n",
    "\n",
    "VGG16/VGG19: Modelos más profundos que AlexNet.\n",
    "ResNet: Introduce bloques residuales para entrenar redes más profundas sin sufrir problemas de degradación de gradientes.\n",
    "EfficientNet: Optimizado para lograr una mejor precisión con menos parámetros y menos coste computacional.\n",
    "DenseNet: Similar a ResNet pero con más conexiones internas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python, puedes usar AlexNet si tu objetivo es aprendizaje o pruebas rápidas, pero para aplicaciones serias, se recomienda usar modelos más recientes como ResNet, VGG, o EfficientNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hay q instalar torch para poder traer alexnet a python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar la red AlexNet preentrenada en el dataset ImageNet\n",
    "net = models.alexnet(pretrained=True)\n",
    "\n",
    "# Poner la red en modo evaluación\n",
    "net.eval()\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features = Esta sección se encarga de extraer características de la imagen de entrada utilizando capas convolucionales y de pooling.\n",
    "Conv2d: Capa de convolución 2D.\n",
    "3: Número de canales de entrada (RGB).\n",
    "64: Número de filtros (salidas) en esta capa.\n",
    "kernel_size: Tamaño del filtro (11x11).\n",
    "stride: El paso que da el filtro en cada dirección (4 píxeles).\n",
    "padding: Añade un borde de 2 píxeles alrededor de la imagen para controlar el tamaño de la salida.\n",
    "\n",
    "Capa de activación ReLU (Rectified Linear Unit) que introduce no linealidad en la red. inplace=True significa que la operación se realiza en el mismo lugar, ahorrando memoria.\n",
    "\n",
    "MaxPool2d:\n",
    "Capa de agrupamiento máximo (pooling) que reduce las dimensiones espaciales de la salida de la convolución.\n",
    "kernel_size: Tamaño de la ventana de pooling (3x3).\n",
    "stride: La ventana se mueve 2 píxeles a la vez.\n",
    "\n",
    "Dropout:\n",
    "Capa de Dropout que se utiliza durante el entrenamiento para evitar el sobreajuste. Aquí, el 50% de las neuronas se \"apagan\" aleatoriamente durante cada paso de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capa de Convolución: Extrae características visuales de la imagen.\n",
    "Capa de ReLU: Introduce no linealidad.\n",
    "Capa de Pooling: Reduce la dimensionalidad y ayuda a prevenir el sobreajuste.\n",
    "Capa de Promedio Adaptativo: Reduce la salida a un tamaño fijo.\n",
    "Clasificación: Conecta las características extraídas a las clases objetivo usando capas lineales y dropout para regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tienes una imagen para procesar, puedes hacerlo así:\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para preparar la imagen (redimensionar, normalizar, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize: Esta transformación redimensiona la imagen para que el lado más corto tenga 256 píxeles, manteniendo la relación de aspecto.\n",
    "Propósito: Asegura que las imágenes de entrada tengan un tamaño coherente, lo que es importante para la entrada a la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "centerCrop: Esta transformación recorta la imagen en el centro a un tamaño de 224x224 píxeles.\n",
    "Propósito: Esto es necesario porque muchos modelos preentrenados, como AlexNet, esperan una entrada de 224x224 píxeles. Al centrar el recorte, se capturan las características más relevantes de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "totensor: Convierte la imagen en un tensor de PyTorch.\n",
    "Propósito: Las redes neuronales en PyTorch trabajan con tensores, no con imágenes directamente. Esta transformación convierte la imagen de formato PIL o NumPy a un tensor de dimensiones (C, H, W) donde C es el número de canales (por ejemplo, 3 para imágenes RGB), H es la altura y W es el ancho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza el tensor usando la media y la desviación estándar proporcionadas para cada canal de color.\n",
    "Propósito: La normalización es un paso crucial porque ayuda a centrar los datos de entrada alrededor de cero y a escalar las características. Esto puede mejorar la convergencia del modelo durante el entrenamiento y mejorar la precisión. Las medias y desviaciones estándar especificadas son las que se calcularon a partir del conjunto de datos ImageNet, que se utilizó para preentrenar muchos modelos, incluido AlexNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CARGAR IMAGEN\n",
    "\n",
    "img_path = 'imagenes/patito.png'  # Cambia a la ruta de tu imagen\n",
    "img = Image.open(img_path)\n",
    "img_t = transform(img)  # Aplicar las transformaciones\n",
    "batch_t = torch.unsqueeze(img_t, 0)  # Añadir una dimensión de batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este código, se asume que tienes un archivo llamado imagenet_classes.json que contiene un diccionario que asigna índices de clase a nombres de clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Realizar la predicción\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 3\u001b[0m     out \u001b[38;5;241m=\u001b[39m net(\u001b[43mbatch_t\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Mostrar el resultado\u001b[39;00m\n\u001b[0;32m      6\u001b[0m _, index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(out, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_t' is not defined"
     ]
    }
   ],
   "source": [
    "# Realizar la predicción\n",
    "with torch.no_grad(): #desactiva el cálculo de gradientes, lo que ahorra memoria y mejora la velocidad de ejecución en la inferencia\n",
    "    out = net(batch_t)\n",
    "\n",
    "# Mostrar el resultado\n",
    "_, index = torch.max(out, 1) #devuelve los valores máximos y los índices a lo largo de la dimensión especificada. Aquí, el índice correspondiente a la clase con la mayor puntuación se utiliza para obtener el nombre de la clase predicha\n",
    "print(f'Predicted class index: {index.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esto solo funcionaria con matlab, aqui hay q tirar con otros modelos\n",
    "[net,classNames] = imagePretrainedNetwork(\"alexnet\");\n",
    "\n",
    "net = imagePretrainedNetwork(\"alexnet\",Weights=\"none\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probamos el modelo resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-50 es un modelo de red neuronal convolucional profunda (CNN) que pertenece a la familia de Redes Residuales (ResNet), introducidas por Kaiming He et al. en su artículo seminal titulado \"Deep Residual Learning for Image Recognition\" en 2015. ResNet fue revolucionario porque resolvió uno de los problemas clave en el entrenamiento de redes profundas: la degradación del rendimiento a medida que se incrementa la profundidad de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectividad en profundidad: Utiliza conexiones residuales que permiten el entrenamiento de redes muy profundas sin degradación del rendimiento.\n",
    "Generalización: Se ha demostrado que ResNet generaliza bien en diversas tareas, incluida la clasificación de imágenes generadas por IA.\n",
    "Uso: Adecuado para un gran número de clases y variaciones en las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet50(pretrained=True)\n",
    "\n",
    "# Poner el modelo en modo evaluación\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tienes imágenes de alta calidad (ya sean reales o generadas por IA), los modelos más avanzados (como EfficientNet o ViT) podrían ofrecer mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si las imágenes generadas por IA son muy similares a las reales, un modelo más simple como ResNet puede ser suficiente. Pero si hay grandes diferencias, puede ser necesario un modelo más complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos más grandes y complejos requieren más recursos para entrenar y hacer inferencias. Debes considerar la disponibilidad de GPUs y tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESAR IMAGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ajustar tamaño\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalizar\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data augmentation \n",
    "técnica esencial en el entrenamiento de modelos de aprendizaje profundo, especialmente en la clasificación de imágenes. Su propósito es aumentar la diversidad del conjunto de entrenamiento sin necesidad de recopilar más datos.\n",
    "\n",
    "Rotación: Girar la imagen en un cierto rango de grados.\n",
    "Cambio de Escala: Cambiar el tamaño de la imagen (acercar o alejar).\n",
    "Desplazamiento (Shift): Desplazar la imagen en direcciones horizontales o verticales.\n",
    "Reflejo (Flip): Voltear la imagen horizontal o verticalmente.\n",
    "Ajuste de Brillo/Contraste: Cambiar el brillo y el contraste de la imagen.\n",
    "Transformaciones de Color: Cambiar la saturación, el tono, etc.\n",
    "Recorte Aleatorio: Recortar secciones aleatorias de la imagen.\n",
    "Ruido Aleatorio: Añadir ruido a la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Definir las transformaciones de aumento de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),  # Rotación aleatoria hasta 15 grados\n",
    "    transforms.RandomHorizontalFlip(),  # Voltear horizontalmente con probabilidad 0.5\n",
    "    #Es especialmente útil para imágenes donde la orientación no es crítica (por ejemplo, objetos)\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),  # Recorte aleatorio \n",
    "    #Recorta una sección aleatoria de la imagen y la redimensiona a un tamaño específico\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Ajustar brillo y contraste\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Cargar el conjunto de datos de entrenamiento con aumento de datos\n",
    "train_dataset = datasets.ImageFolder(root='path to dataset', transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIVIDIR CONJUNTO DE DATOS\n",
    "- ENTRENAMIENTO\n",
    "- VALIDACION\n",
    "- TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELEGIR MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion de perdida y optimizador "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "función de pérdida es una medida de cuán bien está funcionando un modelo en comparación con la verdad conocida (etiquetas) durante el entrenamiento. Cuanto menor sea el valor de la pérdida, mejor será el rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clasificación Binaria: Para problemas donde solo hay dos clases, ia/reales\n",
    "\n",
    "import torch.nn as nn\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "#hay otras para clasificacion multiclase, regresion (predecir el valor de una casa)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento, el modelo realiza una predicción sobre los datos de entrada y luego calcula la pérdida utilizando la función de pérdida definida.\n",
    "La pérdida se utiliza para calcular los gradientes de los parámetros del modelo. Esto se realiza a través del algoritmo de retropropagación (backpropagation).\n",
    "Ajuste de Parámetros: Los parámetros del modelo se ajustan para minimizar la pérdida a través del optimizador, que actualiza los pesos del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizador es un algoritmo que ajusta los parámetros del modelo (los pesos y sesgos) para minimizar la función de pérdida. Su objetivo es encontrar el conjunto óptimo de parámetros que permita que el modelo generalice bien a nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent (SGD): Actualiza los parámetros basándose en un pequeño subconjunto de datos (un batch)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "#Adam: Un optimizador más avanzado que ajusta la tasa de aprendizaje para cada parámetro. Es uno de los más populares por su rapidez y eficiencia.\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#RMSprop: Se utiliza a menudo en redes neuronales recurrentes y ayuda a mitigar problemas de desvanecimiento del gradiente.\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización: Se inicializa el optimizador con los parámetros del modelo y la tasa de aprendizaje (learning rate).\n",
    "Actualización de Parámetros: En cada iteración del ciclo de entrenamiento:\n",
    "Se calculan los gradientes de la función de pérdida con respecto a los parámetros.\n",
    "El optimizador ajusta los parámetros utilizando estos gradientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  #cantidad de veces q el modelo pasara por todo el conj de entrenamiento\n",
    "#numero muy alto podria provocar sobreajuste\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Modo entrenamiento\n",
    "    running_loss = 0.0 #acumula la perdida a lo largo de todas\n",
    "    #las iteraciones \n",
    "\n",
    "    for inputs, labels in train_loader:  # se necesita DataLoader\n",
    "        #imagenes y datos de entrada\n",
    "        optimizer.zero_grad()  #se reinician los gradientes, los gradientes de cada parametro se acumulan\n",
    "\n",
    "        outputs = model(inputs)  # Hacer la predicción\n",
    "        #salida del modelo, predicciones sobre los datos de entrada\n",
    "        loss = criterion(outputs, labels)  # Calculo de la pérdida\n",
    "        loss.backward()  # Retropropagación, calcula los gradientes de la función de pérdida \n",
    "        #con respecto a cada uno de los parámetros del modelo. Es fundamental para actualizar los pesos del modelo de manera efectiva.\n",
    "        optimizer.step()  # Actualizar los pesos\n",
    "\n",
    "        running_loss += loss.item() #acumulacion de perdida\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Modo evaluación\n",
    "correct = 0 #numero de predicciones correctas q el modelo realiza\n",
    "total = 0 #num total de muestras en el conjunto de prueba\n",
    "\n",
    "with torch.no_grad(): #desactiva el cálculo de gradientes en la sección del código que sigue\n",
    "    #Eficiencia: Ahorra memoria y computación, ya que no necesitas calcular gradientes durante la evaluación.\n",
    "    #No Necesario: No estás actualizando los pesos del modelo; solo necesitas realizar predicciones.\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        #inputs se pasa a través del modelo para obtener las predicciones. outputs contendrá las salidas del modelo para el batch actual.\n",
    "        #interpretación de Salidas: outputs suele ser un tensor que contiene las puntuaciones (logits) para cada clase de cada imagen en el batch.\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #devuelve dos valores:\n",
    "#El primero (_) es el valor máximo (no se usa aquí, por eso se ignora).\n",
    "#El segundo (predicted) es el índice de la clase con la puntuación máxima para cada imagen en el batch. Es decir, predicted contendrá la clase que el modelo predice para cada entrada en inputs.\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosas q podemos añadir \n",
    "Regularización: Aplica técnicas como Dropout para prevenir el sobreajuste.\n",
    "Transfer Learning: Experimenta con diferentes modelos preentrenados y ajusta hiperparámetros para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "guardar modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')  # Guardar el estado del modelo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
