Con el objetivo de batir el récord existente hasta entonces (top-5 error del 25%), en el año 2012, Alex Krizhevsky propuso, junto con su director de tesis Geoffrey Hinton, un nuevo modelo de red convolucional que logró reducir ese porcentaje hasta el 17%.. Éste modelo se conocería como AlexNet.

 Su arquitectura se compone de cinco capas convolucionales cuyas salidas son normalizadas por lotes (aunque el esquema de normalización del artículo original era ligeramente diferente). La primera, cuarta y quinta capas convolucionales vienen seguidas cada una de ellas por una capa de agrupación (max-pooling) de 3×3, en la que existe un desplazamiento (stride) de dos, lo que provoca que haya un solapamiento de las celdas de esta capa. Las capas convolucionales y de pooling vienen seguidas de dos capas densas, de 4.096 neuronas cada una, y de una última capa densa de 1.000 neuronas de salida, dotada de la función de activación softmax. Son estas últimas las encargadas de realizar la clasificación de la imagen.